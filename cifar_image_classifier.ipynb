{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 Multi-Class Image Classification\n",
    "\n",
    "- Keras notes https://keras.io/api/datasets/cifar10/\n",
    "- CIFAR detail https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already pre-processed vectorized, already split data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "num_classes = 10\n",
    "input_shape = (32, 32, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label: [6]\n"
     ]
    }
   ],
   "source": [
    "digit = x_train[0]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "print(\"Train label:\", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3, 1)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Make sure images have shape (32, 32, 3, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv2d_4 is incompatible with the layer: expected ndim=4, found ndim=5. Full shape received: [None, 32, 32, 3, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-27996f38c52f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     ]\n\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    194\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[0;32m--> 812\u001b[0;31m                                               self.name)\n\u001b[0m\u001b[1;32m    813\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    175\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv2d_4 is incompatible with the layer: expected ndim=4, found ndim=5. Full shape received: [None, 32, 32, 3, 1]"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 3\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_2 to have 4 dimensions, but got array with shape (50000, 32, 32, 3, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-f0eccfcd2681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    563\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_2 to have 4 dimensions, but got array with shape (50000, 32, 32, 3, 1)"
     ]
    }
   ],
   "source": [
    "# model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
