{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from keras.datasets import fashion_mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label: 0\n"
     ]
    }
   ],
   "source": [
    "digit = x_train[2]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "print(\"Train label:\", y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/3\n",
      "54000/54000 [==============================] - 33s 603us/sample - loss: 0.6915 - accuracy: 0.7534 - val_loss: 0.4397 - val_accuracy: 0.8402\n",
      "Epoch 2/3\n",
      "54000/54000 [==============================] - 31s 576us/sample - loss: 0.4517 - accuracy: 0.8379 - val_loss: 0.3837 - val_accuracy: 0.8663\n",
      "Epoch 3/3\n",
      "54000/54000 [==============================] - 32s 593us/sample - loss: 0.4006 - accuracy: 0.8569 - val_loss: 0.3597 - val_accuracy: 0.8715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x64d8c4278>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 3\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3454024649818738\n",
      "Train accuracy: 0.8783\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on training data\n",
    "loss, accuracy = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Train loss:\", loss)\n",
    "print(\"Train accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3732008759975433\n",
      "Test accuracy: 0.8678\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", loss)\n",
    "print(\"Test accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
